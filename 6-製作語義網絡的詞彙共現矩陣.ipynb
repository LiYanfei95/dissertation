{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdde456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2964d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_list(file_path):\n",
    "    \"輸入以utf-8編碼的txt文件，文件以回車分隔停用詞\"\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        stopwords = f.read().split('\\n')\n",
    "        stopwords = [word.strip() for word in stopwords if word.strip()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97f8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(folder_path):\n",
    "    # 初始化一個空列表來存儲文件路徑\n",
    "    file_paths = []\n",
    "\n",
    "    # 遍歴文件夾及其所有子文件夾\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # 檢查文件是否爲xlsx文件\n",
    "            if file.endswith('.xlsx'):\n",
    "                # 將完整的文件路徑添加到列表中\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_paths.append(file_path)\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7a4b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(folder_path,stopwords,num_keywords=20):\n",
    "    '''\n",
    "    num_keywords是提取多少個tf-idf得分最高的關鍵詞\n",
    "    '''\n",
    "    xlsx_files = get_files(folder_path)\n",
    "    documents = []\n",
    "    big_df = pd.DataFrame(columns=['分詞']) \n",
    "    for file_path in xlsx_files:\n",
    "        print(file_path)\n",
    "        # 讀取文件\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # 檢查是否存在“分詞”列\n",
    "        if '分詞' in df.columns:\n",
    "            # 提取並處理“分詞”列的內容\n",
    "            df = df[df['X'].notna()] # 坐標部分不爲空的行才是地方志數據，其他的是非方志數據\n",
    "            df = df.drop_duplicates(subset=['分詞'])\n",
    "            document = df['分詞'].str.cat(sep=' ')\n",
    "            documents.append(document)\n",
    "            big_df = pd.concat([big_df, df[['分詞']]], ignore_index=True)\n",
    "\n",
    "            \n",
    "    # 使用TfidfVectorizer計算TF-IDF得分\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # 獲取詞彙表\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # 對於每個文檔，選擇得分最高的詞作為關鍵詞\n",
    "    keywords = []\n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        row = tfidf_matrix[i, :].toarray().flatten()\n",
    "        top_indices = row.argsort()[-num_keywords:][::-1]\n",
    "        top_keywords = [feature_names[j] for j in top_indices]\n",
    "        keywords.append(top_keywords)\n",
    "\n",
    "    # 構建共現矩陣\n",
    "    unique_keywords = list(set(keyword for sublist in keywords for keyword in sublist))\n",
    "    keyword_index = {keyword: idx for idx, keyword in enumerate(unique_keywords)}\n",
    "    cooccurrence_matrix = np.zeros((len(unique_keywords), len(unique_keywords)))\n",
    "    \n",
    "    pair_combinations = list(combinations(unique_keywords, 2)) # 關鍵詞的兩兩配對組合\n",
    "    \n",
    "    for keyword1, keyword2 in pair_combinations:\n",
    "        count = (big_df['分詞'].str.contains(keyword1) & big_df['分詞'].str.contains(keyword2)).sum()\n",
    "        cooccurrence_matrix[keyword_index[keyword1], keyword_index[keyword2]] = count\n",
    "\n",
    "    # 將共現矩陣轉換爲DataFrame\n",
    "    cooccurrence_df = pd.DataFrame(cooccurrence_matrix, index=unique_keywords, columns=unique_keywords)\n",
    "    output_path =  os.path.join(folder_path, '關鍵詞共現矩陣.csv')\n",
    "    cooccurrence_df.to_csv(output_path, encoding=\"utf-8\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99dae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords_list(r'F:\\古籍處理數據\\input\\繪圖\\停用詞.txt')\n",
    "folder_path = r'E:\\坚果云同步文件\\论文内容\\博士階段論文\\畢業論文\\論文數據\\語料分析數據\\已篩選-方言\\春季'\n",
    "process_file(folder_path,stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfc9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
